{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "python-text-mining",
      "graded_item_id": "r35En",
      "launcher_item_id": "tCVfW",
      "part_id": "NTVgL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "Spelling Recommender.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanessaaleung/spelling-recommender/blob/main/Spelling_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGHXILgltpJ1"
      },
      "source": [
        "## Spelling Recommender\n",
        "\n",
        "Create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
        "\n",
        "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
        "\n",
        "*Each of the three different recommenders will use a different distance measure (outlined below).*\n",
        "\n",
        "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DThWODpvtpJ2",
        "outputId": "6cd0557a-40a5-4a46-d0fb-cebd00d44399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "correct_spellings = words.words()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISS6kmpmtpJ8"
      },
      "source": [
        "### Jaccard distance - Trigrams\n",
        "\n",
        "Provide recommendations using the **[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words** metric\n",
        "\n",
        "Jaccard distance is obtained by dividing the difference of the sizes of the union and the intersection of two sets by the size of the union"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VOlPXYFtpJ8",
        "outputId": "326a3f88-38a8-42fe-c3bd-1eaec097ecb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def jaccard_distance_trigram(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "    \"\"\"\n",
        "    Distance metric comparing set-similarity\n",
        "    \"\"\"\n",
        "    from nltk.metrics.distance import jaccard_distance\n",
        "    from nltk.util import ngrams\n",
        "    res = []\n",
        "    for ent in entries:\n",
        "        distances = [(word, jaccard_distance(set(ngrams(ent, 3)), set(ngrams(word, 3))))\\\n",
        "                     for word in correct_spellings if word[0] == ent[0]]\n",
        "        res.append(sorted(distances, key=lambda x: x[1])[0][0])\n",
        "    return res\n",
        "    \n",
        "jaccard_distance_trigram()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpulent', 'indecence', 'validate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmCKtWCtpJ_"
      },
      "source": [
        "### Jaccard distance - 4-grams\n",
        "\n",
        "Provide recommendations using the **[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.** metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6dpoof2tpKA",
        "outputId": "f8072b11-4951-4e82-d97d-2512db9e4b89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def jaccard_distance_4gram(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "    \n",
        "    from nltk.metrics.distance import jaccard_distance\n",
        "    from nltk.util import ngrams\n",
        "    res = []\n",
        "    for ent in entries:\n",
        "        distances = [(word, jaccard_distance(set(ngrams(ent, 4)), set(ngrams(word, 4))))\\\n",
        "                     for word in correct_spellings if word[0] == ent[0]]\n",
        "        res.append(sorted(distances, key=lambda x: x[1])[0][0])\n",
        "    return res\n",
        "    \n",
        "jaccard_distance_4gram()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cormus', 'incendiary', 'valid']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZYDYTvrtpKD"
      },
      "source": [
        "### Edit Distance\n",
        "\n",
        "Provide recommendations using the **[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)** metric\n",
        "\n",
        "The edit distance between two words is the minimum number of operations (insertions / deletions / substitutions of a single character, or transposition of two adjacent characters) required to change one word into the other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RBGnL4TtpKE",
        "outputId": "c322035f-1fac-460d-c3f5-4b9df9ded303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def edit_distance_transpositions(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "    \n",
        "    '''\n",
        "    The edit distance is the number of characters that need to be\n",
        "    substituted, inserted, or deleted, to transform s1 into s2\n",
        "    '''\n",
        "    from nltk.metrics.distance import edit_distance\n",
        "    res = []\n",
        "    for ent in entries:\n",
        "        distances = [(word, edit_distance(ent, word))\\\n",
        "                     for word in correct_spellings if word[0] == ent[0]]\n",
        "        res.append(sorted(distances, key=lambda x: x[1])[0][0])\n",
        "    return res\n",
        "    \n",
        "edit_distance_transpositions()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpulent', 'intendence', 'validate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}